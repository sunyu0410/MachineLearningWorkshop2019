{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ml_day3_part_3.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"KtSAO18qrXje","colab_type":"text"},"source":["# Distributed learning (15 minutes)\n","ACPSEM Machine Learning Workshop 2019, 29 - 31 May 2019\n","\n","Yu Sun, yu.sun@sydney.edu.au\n","\n","University of Sydney\n","\n","There are many aspects about distributed learning, e.g.\n","* Map: Given a large dataset, how can we divide the training load to multiple servers? For example, a centralised clinical centre have a large amount of data. It may allocate the resources from several satelite hospitals to do part of the training.\n","* Reduce: If multiple models have been trained seperately, how can we merge the result back? For example, different clinical centres may prefer not to share the data, but instead train a model locally and share the model. Back to the central server, how to use these models to make a consensus decision is the question.\n","\n","In general, these two step is called \"Map-Reduce\". It is a widely used strategy for big data analysis.\n","\n","In this session, we will look at the situation that:\n","* We have a dataset and divide the task to different centres;\n","* Each centre has trained a model locally;\n","* You have all the models and will \"merge\" them to make a decision using majority vote.\n","\n","This tutorial focuses in the data flow instead of the 'merging' technique. "]},{"cell_type":"markdown","metadata":{"id":"2O5a5r6d2_i2","colab_type":"text"},"source":["## Code\n"]},{"cell_type":"code","metadata":{"id":"JO0qnIaTrVb2","colab_type":"code","colab":{}},"source":["# Import libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.datasets import make_moons, make_circles, make_classification\n","from sklearn.svm import SVC\n","from sklearn.model_selection import KFold"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x66k9HAtrlzO","colab_type":"code","colab":{}},"source":["# Generate the dummy data and \n","X, y = make_classification(n_samples=5000, n_features=2, n_redundant=0, \n","                           n_informative=2, random_state=1, \n","                           n_clusters_per_class=1)\n","\n","# Standardise the data (to mean 0, std 1)\n","X = StandardScaler().fit_transform(X)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ls4EpH-xite","colab_type":"code","colab":{}},"source":["# Visualise the data\n","# First we define a function to do the scatter plot\n","def plotData(x, y, title='Title'):\n","  'Scatter plot of the x, colour indicated by y'\n","  import matplotlib.pyplot as plt\n","  import matplotlib.patches as mpatches\n","  plt.style.use('ggplot')\n","  plt.scatter(x[:,0], x[:, 1], \n","              c=y, \n","              cmap=ListedColormap(['orange', 'darkcyan']), # for 0 and 1\n","              edgecolors='k',\n","              s=80)\n","  plt.xlabel('x1')\n","  plt.ylabel('x2')\n","  plt.title(title)\n","  patches = (mpatches.Patch(color='orange', label='Negative'),\n","             mpatches.Patch(color='darkcyan', label='Positive'))\n","  plt.legend(handles=patches)\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hE0aL4nOxTnt","colab_type":"code","colab":{}},"source":["plotData(X, y, 'All data')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-9pj3YEfzr2B","colab_type":"code","colab":{}},"source":["# Hold out some test data for consensus assessment\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n","print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2LEJDgo7xqRh","colab_type":"code","colab":{}},"source":["# We then assign the training data to 4 sites\n","# This could be 4 hospitals in real-world scenarios\n","kf = KFold(n_splits=4)\n","kf.get_n_splits(X_train)\n","site_data = []\n","for _ignore, index in kf.split(X_train):\n","  site_X_train = X_train[index, :]\n","  site_y_train = y_train[index]\n","  site_data.append({'X':site_X_train, 'y':site_y_train})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xDb48DTg0hZk","colab_type":"code","colab":{}},"source":["# Check the number of data for each site\n","print('The row number of data for Site 1 is', site_data[0]['X'].shape[0])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6LHvO4--1Zxu","colab_type":"text"},"source":["It should be 1000, because for the 5000 samples in total, 1000 held out for testing, and 1000 allocated for each of the site.\n","\n","Exercise: check the row number for other sites."]},{"cell_type":"code","metadata":{"id":"f3SeM6R00RgP","colab_type":"code","colab":{}},"source":["# Plot the data for site 1\n","plotData(site_data[0]['X'], site_data[0]['y'], 'Data for Site 1')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ES4GCcn31rqQ","colab_type":"text"},"source":["Exercise: plot the data for other sites, make sure they have similar distributions."]},{"cell_type":"code","metadata":{"id":"I_ZIjzwX3XPZ","colab_type":"code","colab":{}},"source":["# Fit a model using the first site\n","data = site_data[0]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QVlxLgNew9Q8","colab_type":"text"},"source":["Exervise:\n","\n","1. Review the code yesterday `Part 1` to develop a SVM model using the data at site 1. Hint: from site 1 ponit of view, the `data` is all it has. So you have to hold out some data as test data at that site in order to assess the performance.\n","\n","2. Use a `for` loop to develop the models for the remaning sites and save all models in an object called `models`;\n","\n","3. For the test data we held out for consensus testing (`X_test` and `y_test`). For each sample, you will have a prediction from each of the models at 4 sites. Use a majority vote to decide the consensus decision. For example, if 3 models predict as \"positive\" (1), 1 predicts as \"negative\" (0), decision is \"positive\""]},{"cell_type":"markdown","metadata":{"id":"0KGjmLvPyiOc","colab_type":"text"},"source":["\n","\n","---\n","\n","This is the end of this session."]}]}