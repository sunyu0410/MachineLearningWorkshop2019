{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ml_day3_part_1.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"GYME_gIdgmQu","colab_type":"text"},"source":["# Neural network (45 minutes)\n","ACPSEM Machine Learning Workshop 2019, 29 - 31 May 2019\n","\n","Yu Sun, yu.sun@sydney.edu.au\n","\n","University of Sydney\n","\n","In this session, we will look at fully connect neural network in these aspects:\n","\n","* trainable parameters\n","* learning compacity\n","* activation functions\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2AOocA7c4bXt","colab_type":"text"},"source":["## Data (10 minutes)\n","First let's generate some data for the learning task. We will use the functions in `sklearn` to do that."]},{"cell_type":"code","metadata":{"id":"7t6t4QqJhpGJ","colab_type":"code","colab":{}},"source":["# Import sklearn and components in matplotlib\n","from sklearn import datasets\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","import matplotlib.patches as mpatches\n","plt.style.use('ggplot')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xTTtNuubhvD8","colab_type":"code","colab":{}},"source":["# Generate the data\n","#  By default it's a 2D dataset \n","#  (i.e. two features and one label for each sample)\n","X, y = datasets.make_circles(noise=0.2, factor=0.5, random_state=1)\n","# Normalisation\n","X = (X - X.mean(0)) / X.std(0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WZ4-sgEG4iH9","colab_type":"code","colab":{}},"source":["# Visualise the data\n","# First we define a function to do the scatter plot\n","def plotData(x, y, title='Title'):\n","  'Scatter plot of the x, colour indicated by y'\n","  plt.scatter(x[:,0], x[:, 1], \n","              c=y, \n","              cmap=ListedColormap(['orange', 'darkcyan']), # for 0 and 1\n","              edgecolors='k',\n","              s=50)\n","  plt.xlabel('x1')\n","  plt.ylabel('x2')\n","  plt.title(title)\n","  patches = (mpatches.Patch(color='orange', label='Negative'),\n","             mpatches.Patch(color='darkcyan', label='Positive'))\n","  plt.legend(handles=patches)\n","  plt.show()\n","\n","# Plot the data\n","plotData(X, y, 'All data')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6dvSHIB8lQI0","colab_type":"code","colab":{}},"source":["# Data partitioning\n","#  Split into training data and test data\n","from sklearn.model_selection import train_test_split\n","trData, tsData, trLabel, tsLabel = train_test_split(X, y, \n","                                                    random_state=0,\n","                                                    test_size=0.3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ho3LmEAdnPUm","colab_type":"code","colab":{}},"source":["# Plot the training data\n","#  and also test the plotData() function\n","plotData(trData, trLabel, 'Training data only')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fcHJf2Na49_z","colab_type":"text"},"source":["## Trainable parameters (5 minutes)\n","(This is a on-paper exercise.)\n","\n","We have generated the data (2D), which goes directly into the input layer of the neural network. We also know the output which is one neuron. Hence given the hidden layer structure, we can compute the trainable parameters.\n","\n","Draw the structure of the network and compute the number of trainable parameters for the following hidden layers:\n","  * (5, 1)\n","  * (2, 4)\n","  * (4, 2)\n","  * (1, 5)\n","  \n","What pattern do you find? Discuss with your neighbours."]},{"cell_type":"markdown","metadata":{"id":"kwMV5BOq7Soc","colab_type":"text"},"source":["## Learning capacity (20 minutes)\n","Let's defined our first network and fit the data. The `score()` method will return the accuracy given the test data and test labels."]},{"cell_type":"code","metadata":{"id":"aKT0DZg6mRK_","colab_type":"code","colab":{}},"source":["# Define the first network\n","# Import the neural network class\n","from sklearn import neural_network\n","\n","# Define the network\n","# Key argument is the hidden_layer_sizes\n","nn = neural_network.MLPClassifier(activation='relu',\n","                                  hidden_layer_sizes=(50,50,10),\n","                                  random_state=0,\n","                                  solver='sgd',\n","                                  max_iter=50000)\n","\n","# Fit the model\n","nn.fit(trData, trLabel)\n","\n","# Get the accuracy\n","score = nn.score(tsData, tsLabel)\n","print(\"The model achieved an accuracy of %.2f\" % score)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k-RJSnPw75UK","colab_type":"code","colab":{}},"source":["# The score is calculated as:\n","pred = nn.predict(tsData)\n","acc = (pred == tsLabel).sum() / len(pred)\n","print(\"Manual calculation of the accuracy: %.2f\" % acc)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YKosPdDSmd1J","colab_type":"code","colab":{}},"source":["# Print out the hidden layer structure\n","nn.hidden_layer_sizes"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vLi6-O8L9PlU","colab_type":"text"},"source":["We can define a function to plot the decision boundary (method referred to [this sklearn example](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py))."]},{"cell_type":"code","metadata":{"id":"A4PsxF-czJhM","colab_type":"code","colab":{}},"source":["# Import numpy\n","import numpy as np\n","\n","def plotDecBnd(nn, title=\"title\"):\n","  'Plot the decision boundary.'\n","  \n","  # Creating the grid\n","  x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n","  y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n","  xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n","                           np.arange(y_min, y_max, 0.5))\n","  Z = nn.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n","\n","  # Plot the grid\n","  Z = Z.reshape(xx.shape)\n","  plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlGn, alpha=.8)\n","  \n","  # Plot the training data\n","  plt.scatter(trData[:, 0], trData[:, 1], c=trLabel,\n","              cmap=ListedColormap(['orange', 'darkcyan']),\n","              edgecolors='w', s=80)\n","  \n","  # Plot the testing data\n","  # Test data has a smaller shape (s=40)\n","  plt.scatter(tsData[:, 0], tsData[:, 1], c=tsLabel, \n","              cmap=ListedColormap(['orange', 'darkcyan']),\n","              edgecolors='w', alpha=0.6, s=40) \n","  patches = (mpatches.Patch(color='orange', label='Negative'),\n","             mpatches.Patch(color='darkcyan', label='Positive'))\n","  plt.legend(handles=patches)\n","  plt.title(title)\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f3nKmLqr4V-f","colab_type":"code","colab":{}},"source":["# Plot the decision boundary\n","plotDecBnd(nn, 'relu, %s, acc=%.2f' % (nn.hidden_layer_sizes, score))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GJ_eQk5W96E3","colab_type":"text"},"source":["Exercise:\n","* Create another network (refer to the code above)\n","* Modify the hidden layer structure\n","* Fit the model and calculate the accuracy\n","* Plot the decsion boundary and observe the difference\n","\n","Use the [playground](https://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.21726&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false) to assess the learning capacity and the network structure."]},{"cell_type":"markdown","metadata":{"id":"RkbmComQ-d_N","colab_type":"text"},"source":["## Activation function (10 minutes)\n","This part examines the choice of an activation function. In the previous example, we used the `relu` (retified linear unit) as the activation function. Let's now change that to an identity function (i.e. no activation function), and observe the consequence."]},{"cell_type":"code","metadata":{"id":"IA4BbLEg-beB","colab_type":"code","colab":{}},"source":["# No activation function\n","nn_linear = neural_network.MLPClassifier(activation='identity',\n","                                         hidden_layer_sizes=(10,10),\n","                                         random_state=0,\n","                                         max_iter=10000)\n","\n","# Fit the model\n","nn_linear.fit(trData, trLabel)\n","\n","# Get the accuracy\n","score_linear = nn_linear.score(tsData, tsLabel)\n","print(\"The model achieved an accuracy of %.2f\" % score_linear)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pAMRVZ4UAjBF","colab_type":"code","colab":{}},"source":["# Plot the decision boundary\n","plotDecBnd(nn_linear, 'identity, %s, acc=%.2f' % (nn.hidden_layer_sizes, \n","                                              score_linear))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a6fJMP_2IA7I","colab_type":"text"},"source":["Try other options for activation functions:\n","* tanh\n","* logistic"]},{"cell_type":"markdown","metadata":{"id":"aUj-ukIUINXw","colab_type":"text"},"source":["\n","\n","---\n","\n","\n","This is the end of this tutorial."]}]}